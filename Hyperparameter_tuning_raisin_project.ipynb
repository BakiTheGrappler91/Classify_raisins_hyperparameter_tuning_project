{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3ff0c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62303866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity',\n",
      "       'ConvexArea', 'Extent', 'Perimeter'],\n",
      "      dtype='object')\n",
      "Area               900\n",
      "MajorAxisLength    900\n",
      "MinorAxisLength    900\n",
      "Eccentricity       900\n",
      "ConvexArea         900\n",
      "Extent             900\n",
      "Perimeter          900\n",
      "dtype: int64\n",
      "['Kecimen' 'Besni']\n",
      "   Class\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "Class\n",
      "0        450\n",
      "1        450\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "raisins = pd.read_excel(\"Raisin_Dataset.xlsx\")\n",
    "#  print(raisins.head())\n",
    "\n",
    "X = raisins.drop(columns='Class')\n",
    "y = raisins['Class']\n",
    "\n",
    "print(X.columns)\n",
    "print(X.count())\n",
    "print(y.unique())\n",
    "\n",
    "#  Convert categorical variable values for class into binary.  0 = 'Besni' and 1 = 'Kecimen'.\n",
    "y = pd.get_dummies(y, columns='Class')\n",
    "y = y.drop(columns='Besni')\n",
    "y = y.rename(columns={'Kecimen' : 'Class'})\n",
    "print(y.head())\n",
    "\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d59409d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=5)\n",
      "0.8666666666666668\n",
      "0.8133333333333334\n",
      "   Accuracy  max_depth  min_samples_split\n",
      "0  0.859259          3                  2\n",
      "1  0.860741          3                  3\n",
      "2  0.860741          3                  4\n",
      "3  0.866667          5                  2\n",
      "4  0.866667          5                  3\n",
      "5  0.863704          5                  4\n",
      "6  0.841481          7                  2\n",
      "7  0.850370          7                  3\n",
      "8  0.842963          7                  4\n"
     ]
    }
   ],
   "source": [
    "#  Split data into train and test datasets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=19)\n",
    "\n",
    "#  Initialize a decision tree classifier.\n",
    "tree = DecisionTreeClassifier()\n",
    "parameters = {'max_depth' : [3, 5, 7], 'min_samples_split' : [2, 3, 4]}\n",
    "grid = GridSearchCV(tree, param_grid=parameters)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "#  Model analysis.\n",
    "best_model = grid.best_estimator_\n",
    "best_score = grid.best_score_\n",
    "print(best_model)\n",
    "print(best_score)\n",
    "test_score = grid.score(X_test, y_test)\n",
    "print(test_score)\n",
    "\n",
    "test_scores = pd.DataFrame(grid.cv_results_['mean_test_score'], columns=['Accuracy'])\n",
    "params = pd.DataFrame(grid.cv_results_['params'])\n",
    "\n",
    "scores_params = pd.concat([test_scores, params], axis=1)\n",
    "print(scores_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d96b954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Class\n",
      "392      1\n",
      "615      0\n",
      "100      1\n",
      "542      0\n",
      "657      0\n",
      "..     ...\n",
      "19       1\n",
      "354      1\n",
      "757      0\n",
      "622      0\n",
      "605      0\n",
      "\n",
      "[675 rows x 1 columns]\n",
      "LogisticRegression(C=22.527423736652718, max_iter=1000, penalty='l1',\n",
      "                   solver='liblinear')\n",
      "0.8755555555555556\n",
      "           C penalty  Accuracy\n",
      "0  22.527424      l1  0.875556\n",
      "1  14.815681      l2  0.875556\n",
      "2  22.747425      l2  0.874074\n",
      "3  45.178235      l1  0.875556\n",
      "4  39.084317      l2  0.874074\n",
      "5  39.982112      l2  0.875556\n",
      "6   7.007522      l1  0.875556\n",
      "7  78.167209      l2  0.875556\n"
     ]
    }
   ],
   "source": [
    "#  Random search hyperparameter tuning.\n",
    "lr = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "distributions = {'penalty' : ['l1', 'l2'], 'C' : uniform(loc=0, scale=100)}\n",
    "clf = RandomizedSearchCV(estimator=lr, param_distributions=distributions, n_iter=8)\n",
    "\n",
    "print(y_train)\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)\n",
    "\n",
    "RandSearch_table = pd.concat([pd.DataFrame(clf.cv_results_['params']), pd.DataFrame(clf.cv_results_['mean_test_score'], columns=['Accuracy'])], axis=1)\n",
    "print(RandSearch_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
